\documentclass[aspectratio=169]{beamer}
\usetheme{metropolis}
\usepackage{appendixnumberbeamer}
\usepackage{booktabs, hyperref}

\input{mgmt675-style}

\subtitle{MGMT 675: Generative AI for Finance}
\title{Building an AI Agent}
\author{Kerry Back}

\date{}

\begin{document}

\maketitle

% ========================================
% PART 1: WHAT IS AN AGENT?
% ========================================

\begin{frame}{Chatbot vs Agent}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Chatbot}]
\begin{itemize}\small
  \item Receives prompts
  \item Generates text responses
  \item That's it---just conversation
  \item Cannot take actions
  \item Cannot access external data
\end{itemize}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Agent}]
\begin{itemize}\small
  \item Receives prompts
  \item Can generate text \alert{or} request actions
  \item Has access to \textbf{tools}
  \item Can query databases, run code, search web
  \item Takes actions to accomplish goals
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\vspace{0.3cm}
\begin{center}
\alert{An agent is a chatbot with tools}
\end{center}
\end{frame}

\begin{frame}{What Are Tools?}
\begin{shadedbox}
\textbf{Tools} are functions the agent can call to interact with the outside world.
\end{shadedbox}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Example Tools}]
\begin{itemize}\small
  \item Execute SQL queries
  \item Run Python code
  \item Read/write files
  \item Search the web
  \item Send emails
  \item Call APIs
\end{itemize}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{How Tools Work}]
\begin{enumerate}\small
  \item LLM decides to use a tool
  \item Returns tool name + parameters
  \item Agent executes the tool
  \item Result sent back to LLM
  \item LLM continues reasoning
\end{enumerate}
\end{shadedbox}
\end{column}
\end{columns}
\end{frame}

% ========================================
% PART 2: FOUNDATION --- THE API
% ========================================
\section{Foundation: Calling an LLM from Code}

\begin{frame}{The API: Talking to an LLM}
\begin{shadedbox}
An \textbf{API} (Application Programming Interface) lets your code communicate with an LLM service over the internet.
\end{shadedbox}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{How It Works}]
\begin{enumerate}\small
  \item Your code sends a request
  \item Request includes your prompt
  \item LLM processes the prompt
  \item API returns the response
  \item Your code uses the result
\end{enumerate}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{What You Need}]
\begin{itemize}\small
  \item API endpoint (URL)
  \item API key (authentication)
  \item Model name to use
  \item Your prompt/messages
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{OpenRouter: One API, Many Models}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{What is OpenRouter?}]
\begin{itemize}\small
  \item Unified API for 100+ models
  \item OpenAI, Anthropic, Google, Meta, etc.
  \item Single API key for all models
  \item Some models are free!
\end{itemize}
\end{shadedbox}
\vspace{0.3cm}
\begin{center}
\texttt{openrouter.ai}
\end{center}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Free Models on Hugging Face}]
\begin{itemize}\small
  \item Hugging Face hosts open models
  \item OpenRouter provides free access
  \item Examples:
  \begin{itemize}\footnotesize
    \item \texttt{mistralai/mistral-7b-instruct:free}
    \item \texttt{meta-llama/llama-3-8b-instruct:free}
    \item \texttt{google/gemma-7b-it:free}
  \end{itemize}
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{A Single API Call}
\begin{shadedbox}[title=\textbf{Basic Structure}]
\begin{verbatim}
import requests

response = requests.post(
    "https://openrouter.ai/api/v1/chat/completions",
    headers={"Authorization": f"Bearer {API_KEY}"},
    json={
        "model": "mistralai/mistral-7b-instruct:free",
        "messages": [{"role": "user", "content": prompt}]
    }
)
answer = response.json()["choices"][0]["message"]["content"]
\end{verbatim}
\end{shadedbox}
\end{frame}

\begin{frame}[fragile]{Message Format and Conversation History}
\begin{shadedbox}[title=\textbf{Messages Are a List of Dictionaries}]
\begin{verbatim}
messages = [
    {"role": "system", "content": "You are a helpful
        finance tutor..."},
    {"role": "user", "content": "What is a P/E ratio?"},
    {"role": "assistant", "content": "A P/E ratio is..."},
    {"role": "user", "content": "How do I interpret it?"}
]
\end{verbatim}
\end{shadedbox}
\vspace{0.3cm}
\begin{baritemize}\small
  \item Each API call is independent---LLM has no memory
  \item You must send the \alert{entire conversation history} each time
  \item The \textbf{system prompt} (role \texttt{system}) defines the agent's behavior
\end{baritemize}
\end{frame}

% ========================================
% PART 3: THE AGENT LOOP
% ========================================
\section{The Agent Loop}

\begin{frame}{The Agent Loop}
\begin{shadedbox}
The agent runs in a loop: LLM thinks $\rightarrow$ tool executes $\rightarrow$ result returns $\rightarrow$ LLM thinks again.
\end{shadedbox}
\vspace{0.3cm}
\begin{center}
\begin{tabular}{ccc}
& \textbf{Tool Call} & \\
\fbox{\textbf{LLM}} & $\longrightarrow$ & \fbox{\textbf{Tool}} \\
& $\longleftarrow$ & \\
& \textbf{Result} & \\
\end{tabular}
\end{center}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{baritemize}\small
  \item LLM decides next action
  \item Returns tool name + parameters
  \item Agent executes the tool
\end{baritemize}
\end{column}
\begin{column}{0.5\textwidth}
\begin{baritemize}\small
  \item Result added to message history
  \item LLM sees result, reasons again
  \item Loop continues until task complete
\end{baritemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{Agent Loop Pseudocode}
\begin{shadedbox}[title=\textbf{The Agent's Decision Loop}]
\begin{verbatim}
while not done:
    response = call_llm(messages, system_prompt, tools)

    if response.has_tool_call:
        result = execute_tool(response.tool_call)
        messages.append(tool_result)
    elif response.needs_user_input:
        answer = ask_user(response.question)
        messages.append(user_answer)
    elif response.is_final:
        done = True
        return response.content
\end{verbatim}
\end{shadedbox}
\vspace{0.2cm}
\begin{center}
\alert{The agent is part LLM intelligence, part traditional programming}
\end{center}
\end{frame}

% ========================================
% PART 4: BUILDING AN AGENT STEP BY STEP
% ========================================
\section{Building an Agent Step by Step}

\begin{frame}{The Key Pieces}
\begin{shadedbox}
To build an agent, you need five components:
\end{shadedbox}
\vspace{0.3cm}
\begin{barenumerate}
  \item \textbf{Define tools}: What actions can the agent take?
  \item \textbf{Write a system prompt}: Describe available tools, schema, and rules
  \item \textbf{Implement the agent loop}: Send messages, parse tool calls, execute, repeat
  \item \textbf{Handle tool execution}: Safely run SQL, Python, etc.
  \item \textbf{Manage context}: Keep message history, handle token limits
\end{barenumerate}
\vspace{0.3cm}
\begin{center}
\alert{Or use an agent framework: LangChain, CrewAI, Claude Code SDK}
\end{center}
\end{frame}

\begin{frame}{Example: Database Analytics Agent}
\begin{shadedbox}
User request: ``Analyze quarterly revenue trends for our top 5 customers and create a summary report.''
\end{shadedbox}
\vspace{0.3cm}
\begin{shadedbox}[title=\textbf{What the Agent Needs to Do}]
\begin{enumerate}\small
  \item Write SQL to identify top 5 customers by revenue
  \item Execute the SQL query against the database
  \item Write SQL to get quarterly revenue for those customers
  \item Execute that query
  \item Write Python to analyze trends and create visualizations
  \item Execute the Python code
  \item Analyze the results
  \item Generate a written report for the user
\end{enumerate}
\end{shadedbox}
\end{frame}

\begin{frame}{Step 1: User Prompt Arrives}
\begin{shadedbox}[title=\textbf{Messages Sent to LLM}]
\begin{tabular}{ll}
\textbf{Role} & \textbf{Content} \\
\midrule
system & You are a data analyst with SQL and Python tools... \\
user & Analyze quarterly revenue trends for top 5 customers... \\
\end{tabular}
\end{shadedbox}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{baritemize}\small
  \item System prompt defines capabilities
  \item Lists available tools
  \item Specifies database schema
  \item Sets response format
\end{baritemize}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{LLM Decides}]
``I need to first find the top 5 customers. I'll write a SQL query.''
\end{shadedbox}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]{Step 2: LLM Requests SQL Tool}
\begin{shadedbox}[title=\textbf{LLM Response (Not Text---A Tool Call)}]
\begin{verbatim}
{
  "tool": "execute_sql",
  "parameters": {
    "query": "SELECT customer_id, SUM(amount) as total
              FROM sales GROUP BY customer_id
              ORDER BY total DESC LIMIT 5"
  }
}
\end{verbatim}
\end{shadedbox}
\vspace{0.3cm}
\begin{baritemize}\small
  \item LLM doesn't return text to user yet
  \item Instead, requests a tool execution
  \item Agent code intercepts this and runs the SQL
  \item Database returns results
\end{baritemize}
\end{frame}

\begin{frame}[fragile]{Step 3: Tool Result Returns to LLM}
\begin{shadedbox}[title=\textbf{Messages Now Include Tool Result}]
\begin{verbatim}
[
  {"role": "system", "content": "You are a data analyst..."},
  {"role": "user", "content": "Analyze quarterly revenue..."},
  {"role": "assistant", "tool_call": "execute_sql(...)"},
  {"role": "tool", "content": "customer_id,total\n
                               ACME,450000\nGlobex,380000\n..."}
]
\end{verbatim}
\end{shadedbox}
\vspace{0.3cm}
\begin{center}
\alert{The LLM sees the full history including tool results}
\end{center}
\end{frame}

\begin{frame}{Step 4: LLM Continues Reasoning}
\begin{shadedbox}
With the top 5 customers identified, the LLM decides what to do next.
\end{shadedbox}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{LLM Thinks}]
``I have the top 5 customers: ACME, Globex, Initech, Umbrella, Wayne. Now I need quarterly data for each.''
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Next Tool Call}]
\texttt{execute\_sql}: Get quarterly revenue for these 5 customers...
\end{shadedbox}
\end{column}
\end{columns}
\vspace{0.3cm}
\begin{center}
The loop continues: tool call $\rightarrow$ result $\rightarrow$ reasoning $\rightarrow$ next action
\end{center}
\end{frame}

\begin{frame}{The Complete Message History}
\begin{shadedbox}[title=\textbf{What the LLM Sees at Report Time}]
\begin{center}
\begin{tabular}{cl}
\# & \textbf{Message} \\
\midrule
1 & system: You are a data analyst... \\
2 & user: Analyze quarterly revenue... \\
3 & assistant: [tool call: SQL for top 5] \\
4 & tool: [results: ACME, Globex...] \\
5 & assistant: [tool call: SQL for quarterly data] \\
6 & tool: [results: Q1, Q2, Q3...] \\
7 & assistant: [tool call: Python analysis] \\
8 & tool: [output: stats, saved trends.png] \\
9 & assistant: Here is my analysis... (final report)
\end{tabular}
\end{center}
\end{shadedbox}
\end{frame}

% ========================================
% PART 5: REAL EXAMPLE --- RICE DATA PORTAL
% ========================================
\section{Example: Rice Data Portal}

\begin{frame}{Rice Data Portal: A Database Agent}
\begin{columns}
\begin{column}{0.4\textwidth}
  \vskip\baselineskip
\begin{baritemize}\small
  \item Prompt + System Prompt $\rightarrow$ LLM
  \item LLM $\rightarrow$ SQL code or a question for the user
  \item Agent $\rightarrow$ SQL code to database or $\rightarrow$ question to the user
  \item Eventually, SQL code $\rightarrow$ database
  \item Database $\rightarrow$ data or error message
  \item Error message $\rightarrow$ LLM
  \item Eventually data $\rightarrow$ user
\end{baritemize}
\end{column}
\begin{column}{0.6\textwidth}
\vspace{1cm}
\begin{shadedbox}\begin{center}
  Visit \href{https://data-portal.rice-business.org}{data-portal.rice-business.org}
  \newline Get access token, Log in, Ask for data
\end{center}\end{shadedbox}
\vspace*{-2\baselineskip}
\includegraphics[width=\textwidth]{images/agent_database.png}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{How the Data Portal is Built}
\begin{baritemize}
  \item System prompt provides the database schema and instructions to the LLM
  \item Agent logic is hard-coded as ``if \ldots\ then \ldots'' (\alert{not AI})
  \item The LLM writes SQL; the agent executes it
  \item If the database returns an error, the agent sends it back to the LLM to try again
  \item If the LLM needs clarification, the agent displays the question to the user
\end{baritemize}
\vspace{0.3cm}
\begin{shadedbox}[title=\textbf{Architecture}]
\begin{center}
\begin{tabular}{ll}
\textbf{Component} & \textbf{Implementation} \\
\midrule
LLM & OpenRouter API (various models) \\
Tool & SQL query execution against PostgreSQL \\
Agent Loop & Python if/else logic \\
UI & Streamlit web interface \\
\end{tabular}
\end{center}
\end{shadedbox}
\end{frame}

% ========================================
% PART 6: UI AND ORCHESTRATION
% ========================================
\section{User Interface and Deployment}

\begin{frame}{Adding a User Interface}
\begin{shadedbox}
An agent doesn't need a web UI---it can run in a terminal or as a script. But a UI makes it accessible to non-technical users.
\end{shadedbox}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Streamlit}]
\begin{itemize}\small
  \item Python library for web apps
  \item No HTML/CSS/JavaScript needed
  \item Built-in chat UI components
  \item Great for data apps and dashboards
  \item \url{streamlit.io}
\end{itemize}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Gradio}]
\begin{itemize}\small
  \item Python library for ML demos
  \item Even simpler chat interface
  \item Built-in sharing via public links
  \item Popular in the ML community
  \item \url{gradio.app}
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\vspace{0.3cm}
\begin{center}
\alert{Both let you build a chat UI in a few lines of Python---no web development skills required}
\end{center}
\end{frame}

\begin{frame}{With or Without a UI}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Without UI (Terminal)}]
\begin{itemize}\small
  \item Agent runs in a Python script
  \item User types prompts at the command line
  \item Results printed to the terminal
  \item Simple, fast to develop
  \item Good for personal tools and scripts
\end{itemize}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{With Streamlit/Gradio UI}]
\begin{itemize}\small
  \item Agent wrapped in a web interface
  \item Chat bubbles, file uploads, charts
  \item Shareable via URL
  \item Accessible to non-technical users
  \item Good for team tools and demos
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\vspace{0.3cm}
\begin{shadedbox}
The \textbf{agent logic is the same} either way. Streamlit and Gradio only handle how the user interacts with the agent---they don't change how the agent works.
\end{shadedbox}
\end{frame}

\begin{frame}{From Idea to Deployed Agent}
\begin{shadedbox}
The complete workflow to build and deploy an agent---all handled by Claude Code with natural language requests.
\end{shadedbox}
\vspace{0.3cm}
\begin{barenumerate}
  \item \textbf{Build the agent}: Define tools, system prompt, and agent loop
  \item \textbf{Add a UI} (optional): Wrap with Streamlit or Gradio
  \item \textbf{Create a GitHub repository}: Version control and collaboration
  \item \textbf{Deploy}: Push to a cloud platform (e.g., Koyeb) for a public URL
  \item \textbf{Iterate}: Push updates that auto-deploy
\end{barenumerate}
\vspace{0.3cm}
\begin{center}
\alert{Ask Claude Code to do each step---no commands to memorize}
\end{center}
\end{frame}

% ========================================
% PART 7: ORCHESTRATION
% ========================================
\section{Advanced: Orchestration}

\begin{frame}{The Orchestration Layer}
\begin{shadedbox}
The agent's control logic coordinates everything: which LLM to call, which system prompt to use, and what to do with each response.
\end{shadedbox}
\vspace{0.3cm}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Different Tasks, Different Prompts}]
\begin{itemize}\small
  \item SQL generation $\rightarrow$ database schema prompt
  \item Python analysis $\rightarrow$ data science prompt
  \item Report writing $\rightarrow$ communication prompt
  \item Each task gets specialized instructions
\end{itemize}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Different Tasks, Different LLMs}]
\begin{itemize}\small
  \item Simple classification $\rightarrow$ fast, cheap model
  \item Complex reasoning $\rightarrow$ powerful model
  \item Code generation $\rightarrow$ code-specialized model
  \item Cost and speed optimization
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Claude Code: A General-Purpose Agent}
\begin{columns}
\begin{column}{0.45\textwidth}
\begin{baritemize}\small
  \item Claude Code is itself an agent
  \item LLM: Claude Opus or Sonnet
  \item Built-in tools: file I/O, bash, code execution, web search
  \item Agent logic: built into Claude Code
  \item \alert{Skills} customize it for specific tasks
\end{baritemize}
\end{column}
\begin{column}{0.55\textwidth}
\begin{shadedbox}[title=\textbf{Claude Code Architecture}]
\begin{center}
\begin{tabular}{ll}
\textbf{Component} & \textbf{Provider} \\
\midrule
LLM & Claude Opus/Sonnet \\
Agent Logic & Claude Code app \\
Base Tools & Claude Code app \\
System Prompt & \alert{Skill} \\
Custom Tools & \alert{Skill scripts} \\
\end{tabular}
\end{center}
\end{shadedbox}
\end{column}
\end{columns}
\end{frame}

% ========================================
% SUMMARY
% ========================================

\begin{frame}{Summary}
\begin{columns}[T]
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Key Concepts}]
\begin{itemize}\small
  \item Agent = Chatbot + Tools
  \item LLM decides which tools to use
  \item Tool results feed back to LLM
  \item Agent loop orchestrates the flow
  \item Full message history provides context
\end{itemize}
\end{shadedbox}
\end{column}
\begin{column}{0.5\textwidth}
\begin{shadedbox}[title=\textbf{Building Blocks}]
\begin{itemize}\small
  \item API call to an LLM (OpenRouter)
  \item System prompt with tool definitions
  \item Agent loop (while not done)
  \item Tool execution (SQL, Python, etc.)
  \item Optional UI (Streamlit / Gradio)
\end{itemize}
\end{shadedbox}
\end{column}
\end{columns}
\vspace{0.5cm}
\begin{center}
\begin{shadedbox}[width=0.85\textwidth]
\centering
\alert{Agents extend LLMs from conversation to action}
\end{shadedbox}
\end{center}
\end{frame}

\end{document}
